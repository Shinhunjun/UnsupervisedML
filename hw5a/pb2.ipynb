{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading summary file 'LA070190-0073': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/LA070190-0073.txt'\n",
      "Error reading summary file 'AP830325-0143': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/AP830325-0143.txt'\n",
      "Error reading summary file 'LA071589-0076': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/LA071589-0076.txt'\n",
      "Error reading summary file 'FBIS4-4674': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/FBIS4-4674.txt'\n",
      "Error reading summary file 'AP880928-0054': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/AP880928-0054.txt'\n",
      "Error reading summary file 'AP891116-0191': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/AP891116-0191.txt'\n",
      "Error reading summary file 'FT934-10911': [Errno 2] No such file or directory: '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries/FT934-10911.txt'\n",
      "\n",
      "Total documents loaded: 301\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.strip().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "text_dir = '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/text'\n",
    "summaries_dir = '/Users/hunjunsin/Desktop/Jun/Unsupervised/hw5A/DUC2001/Summaries'\n",
    "\n",
    "def load_text_and_summaries(text_dir, summaries_dir):\n",
    "    documents = []\n",
    "    gold_summaries = []\n",
    "    file_names = []\n",
    "    \n",
    "    # Load text files\n",
    "    for root, dirs, files in os.walk(text_dir):\n",
    "        for file in files:\n",
    "            summary_file = os.path.join(summaries_dir, file + '.txt')\n",
    "            \n",
    "            text_path = os.path.join(root, file)\n",
    "            try:\n",
    "                text = extract_text_from_sgml(text_path)\n",
    "                text = preprocess_text(text) \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading text file '{file}': {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Read summary file\n",
    "            try:\n",
    "                with open(summary_file, 'r', encoding='utf-8') as f:\n",
    "                    summary = f.read().replace('Abstract:', '', 1).strip()\n",
    "                    summary = preprocess_text(summary)  \n",
    "            except Exception as e:\n",
    "                print(f\"Error reading summary file '{file}': {e}\")\n",
    "                summary = \"\"\n",
    "                continue\n",
    "            \n",
    "            documents.append(text)\n",
    "            gold_summaries.append(summary)\n",
    "            file_names.append(file)\n",
    "    \n",
    "    print(f\"\\nTotal documents loaded: {len(documents)}\")\n",
    "    return documents, gold_summaries, file_names\n",
    "\n",
    "def extract_text_from_sgml(file_path):\n",
    "    with open(file_path, 'r', encoding='latin1') as f:\n",
    "        raw = f.read()\n",
    "    soup = BeautifulSoup(raw, 'html.parser')\n",
    "    text_tag = soup.find(lambda tag: tag.name and tag.name.lower() == \"text\")\n",
    "    if text_tag is None:\n",
    "        raise ValueError(\"No <text> tag found in the file\")\n",
    "    return text_tag.get_text()\n",
    "\n",
    "documents, gold_summaries, file_names = load_text_and_summaries(text_dir, summaries_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The health department said it is providing tuberculosis testing and treatment for the Human Resources Administration's program for the homeless, and will train staff members on tuberculosis prevention and control. The department also has an established residence for homeless tuberculosis patients, and is working with substance-abuse treatment services to extend tuberculosis prevention in its programs. The Board of Health approved a resolution last year requiring all children entering city schools to be tested. The Health Department estimates that one million New Yorkers may be infected by the TB germ. But only a fraction of a percent of those who have active tuberculosis disease can spread the infection to susceptible individuals. The germ is inactive in more than 99% of those infected. Those at high risk for contracting TB are people whose capacity for resisting infection is weakened, either through diseases such as HIV infection, by drug or alcohol abuse, serious illness such as cancer, or by poor nutrition. The greatest concentration of tuberculosis was in the 25-to-44 age group, accounting for 57% of the total. Men outnumber women two to one in the caseload.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The New York City Health Commissioner said that the number of active cases of tuberculosis in the city in 1990 totaled 3,520, an increase of 38 percent over 1989. The Department said that it was instituting new cure programs, and taking measures to improve tuberculosis prevention programs. Children must be tested before entering school, and homeless centers and substance-abuse centers are getting special attention. The greatest concentration of new cases was in the 25-44 age group. The number of men in the caseload was twice that the number of women. Introduction: NEW YORK -- The incidence of active tuberculosis cases in the city rose 38% in 1990, to 3,520 cases, according to the health commissioner. The commissioner, Dr. Woodrow A. Myers Jr., said that although the increase causes concern, the city Department of Health is \"acting aggressively to halt the epidemic.\" The health department has a high cure rate in its tuberculosis clinics, with more than 70% successfully completing therapy. Dr. Myers said that besides special prevention and intervention strategies for high-risk populations, the city is providing $1.3 million for additional efforts. The health department said it is providing tuberculosis testing and treatment for the Human Resources Administration\\'s program for the homeless, and will train staff members on tuberculosis prevention and control. The department also has an established residence for homeless tuberculosis patients, and is working with substance-abuse treatment services to extend tuberculosis prevention in its programs. The Board of Health approved a resolution last year requiring all children entering city schools to be tested. The Health Department estimates that one million New Yorkers may be infected by the TB germ. But only a fraction of a percent of those who have active tuberculosis disease can spread the infection to susceptible individuals. The germ is inactive in more than 99% of those infected. Those at high risk for contracting TB are people whose capacity for resisting infection is weakened, either through diseases such as HIV infection, by drug or alcohol abuse, serious illness such as cancer, or by poor nutrition. The greatest concentration of tuberculosis was in the 25-to-44 age group, accounting for 57% of the total. Men outnumber women two to one in the caseload. \\x1a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_summaries[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WSJ910304-0002'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/hunjunsin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/hunjunsin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "import math\n",
    "from itertools import combinations\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#word distribution\n",
    "def get_word_distribution(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    words = [w for w in words if w not in stopwords.words('english')]\n",
    "    words = [w for w in words if w not in string.punctuation]\n",
    "    total = len(words)\n",
    "    counter = Counter(words)\n",
    "    return {w: c / total for w, c in counter.items()} if total > 0 else {}\n",
    "\n",
    "def kl_divergence(p, q, epsilon=1e-6):\n",
    "    vocab = set(p.keys()).union(set(q.keys()))\n",
    "    return sum(p[w] * math.log(p[w] / q.get(w, epsilon)) for w in vocab if p[w] > 0)\n",
    "\n",
    "def klsum_word_based_greedy(text, max_sentences=3):\n",
    "    sentences = sent_tokenize(text)\n",
    "    if len(sentences) <= max_sentences:\n",
    "        return ' '.join(sentences)\n",
    "    \n",
    "    PD = get_word_distribution(text)\n",
    "    selected = []\n",
    "    remaining = [s.strip() for s in sentences]\n",
    "\n",
    "    for _ in range(max_sentences):\n",
    "        best_sent = None\n",
    "        best_score = float('inf')\n",
    "\n",
    "        for sent in remaining:\n",
    "            candidate_summary = ' '.join(selected + [sent])\n",
    "            PS = get_word_distribution(candidate_summary)\n",
    "            score = kl_divergence(PD, PS)\n",
    "\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_sent = sent\n",
    "\n",
    "        if best_sent:\n",
    "            selected.append(best_sent)\n",
    "            remaining.remove(best_sent)\n",
    "    \n",
    "    return ' '.join(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The health department said it is providing tuberculosis testing and treatment for the Human Resources Administration's program for the homeless, and will train staff members on tuberculosis prevention and control. The department also has an established residence for homeless tuberculosis patients, and is working with substance-abuse treatment services to extend tuberculosis prevention in its programs. The Board of Health approved a resolution last year requiring all children entering city schools to be tested. The Health Department estimates that one million New Yorkers may be infected by the TB germ. But only a fraction of a percent of those who have active tuberculosis disease can spread the infection to susceptible individuals. The germ is inactive in more than 99% of those infected. Those at high risk for contracting TB are people whose capacity for resisting infection is weakened, either through diseases such as HIV infection, by drug or alcohol abuse, serious illness such as cancer, or by poor nutrition. The greatest concentration of tuberculosis was in the 25-to-44 age group, accounting for 57% of the total. Men outnumber women two to one in the caseload.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences : 9\n",
      "Summary sentences (25%): 3\n",
      "Generated summary:\n",
      " The health department said it is providing tuberculosis testing and treatment for the Human Resources Administration's program for the homeless, and will train staff members on tuberculosis prevention and control. Those at high risk for contracting TB are people whose capacity for resisting infection is weakened, either through diseases such as HIV infection, by drug or alcohol abuse, serious illness such as cancer, or by poor nutrition. The Health Department estimates that one million New Yorkers may be infected by the TB germ.\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "document = documents[10]\n",
    "\n",
    "sentences = sent_tokenize(document)\n",
    "num_sentences = len(sentences)\n",
    "\n",
    "max_sentences = ceil(num_sentences * 0.25)\n",
    "\n",
    "summary = klsum_word_based_greedy(document, max_sentences=max_sentences)\n",
    "\n",
    "print(\"Total sentences :\", num_sentences)\n",
    "print(\"Summary sentences (25%):\", max_sentences)\n",
    "print(\"Generated summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [16:00<00:00,  3.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Average ROUGE score]\n",
      "ROUGE-1 F1: 0.6064\n",
      "ROUGE-2 F1: 0.5027\n",
      "ROUGE-L F1: 0.6060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge_scores = []\n",
    "\n",
    "min_tokens = 5\n",
    "\n",
    "for i, (doc_text, gold_summary, fileName) in enumerate(tqdm(zip(documents, gold_summaries, file_names), total=len(documents))):\n",
    "\n",
    "    sentences = sent_tokenize(doc_text)\n",
    "    num_sentences = len(sentences)\n",
    "    max_sentences = ceil(num_sentences * 0.25)\n",
    "\n",
    "    try:\n",
    "        pred_summary = klsum_word_based_greedy(doc_text, max_sentences=max_sentences)\n",
    "    except Exception as e:\n",
    "        continue\n",
    "\n",
    "    pred_summary_clean = str(pred_summary).strip().replace('\\n', ' ')\n",
    "    gold_summary_clean = str(gold_summary).strip().replace('\\n', ' ')\n",
    "\n",
    "\n",
    "    if len(gold_summary_clean.split()) < min_tokens:\n",
    "        print(f\"Skipping file '{fileName}' due to short gold summary.\")\n",
    "        continue\n",
    "    if len(pred_summary_clean.split()) < min_tokens:\n",
    "        print(f\"Skipping file '{fileName}' due to short predicted summary.\")\n",
    "        continue\n",
    "    \n",
    "    scores = rouge.get_scores(pred_summary_clean, gold_summary_clean)[0]  \n",
    "    rouge_scores.append((fileName, scores))\n",
    "\n",
    "if rouge_scores:\n",
    "    all_scores = [s for _, s in rouge_scores]\n",
    "    avg_scores = {\n",
    "        \"rouge-1\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "        \"rouge-2\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "        \"rouge-l\": {\"f\": 0, \"p\": 0, \"r\": 0},\n",
    "    }\n",
    "\n",
    "    for s in all_scores:\n",
    "        for key in avg_scores:\n",
    "            for metric in avg_scores[key]:\n",
    "                avg_scores[key][metric] += s[key][metric]\n",
    "\n",
    "    for key in avg_scores:\n",
    "        for metric in avg_scores[key]:\n",
    "            avg_scores[key][metric] /= len(all_scores)\n",
    "\n",
    "    print(\"\\n[Average ROUGE score]\")\n",
    "    for key in avg_scores:\n",
    "        f1 = avg_scores[key][\"f\"]\n",
    "        print(f\"{key.upper()} F1: {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B: Topic distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "processed_docs = [preprocess_string(doc) for doc in documents] # tokenize, lemmitize, stopword\n",
    "\n",
    "dictionary = Dictionary(processed_docs) # word : id\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_docs] # bag of words\n",
    "\n",
    "lda_model = LdaModel(corpus, num_topics=30, id2word=dictionary, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n   The health department said it is providing tuberculosis\\ntesting and treatment for the Human Resources\\nAdministration's program for the homeless, and will train\\nstaff members on tuberculosis prevention and control. The\\ndepartment also has an established residence for homeless\\ntuberculosis patients, and is working with substance-abuse\\ntreatment services to extend tuberculosis prevention in its\\nprograms. The Board of Health approved a resolution last year\\nrequiring all children entering city schools to be tested.\\n   The Health Department estimates that one million New\\nYorkers may be infected by the TB germ. But only a fraction\\nof a percent of those who have active tuberculosis disease\\ncan spread the infection to susceptible individuals. The germ\\nis inactive in more than 99% of those infected.\\n   Those at high risk for contracting TB are people whose\\ncapacity for resisting infection is weakened, either through\\ndiseases such as HIV infection, by drug or alcohol abuse,\\nserious illness such as cancer, or by poor nutrition. The\\ngreatest concentration of tuberculosis was in the 25-to-44\\nage group, accounting for 57% of the total. Men outnumber\\nwomen two to one in the caseload.\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['health',\n",
       " 'depart',\n",
       " 'said',\n",
       " 'provid',\n",
       " 'tuberculosi',\n",
       " 'test',\n",
       " 'treatment',\n",
       " 'human',\n",
       " 'resourc',\n",
       " 'administr',\n",
       " 'program',\n",
       " 'homeless',\n",
       " 'train',\n",
       " 'staff',\n",
       " 'member',\n",
       " 'tuberculosi',\n",
       " 'prevent',\n",
       " 'control',\n",
       " 'depart',\n",
       " 'establish',\n",
       " 'resid',\n",
       " 'homeless',\n",
       " 'tuberculosi',\n",
       " 'patient',\n",
       " 'work',\n",
       " 'substanc',\n",
       " 'abus',\n",
       " 'treatment',\n",
       " 'servic',\n",
       " 'extend',\n",
       " 'tuberculosi',\n",
       " 'prevent',\n",
       " 'program',\n",
       " 'board',\n",
       " 'health',\n",
       " 'approv',\n",
       " 'resolut',\n",
       " 'year',\n",
       " 'requir',\n",
       " 'children',\n",
       " 'enter',\n",
       " 'citi',\n",
       " 'school',\n",
       " 'test',\n",
       " 'health',\n",
       " 'depart',\n",
       " 'estim',\n",
       " 'million',\n",
       " 'new',\n",
       " 'yorker',\n",
       " 'infect',\n",
       " 'germ',\n",
       " 'fraction',\n",
       " 'percent',\n",
       " 'activ',\n",
       " 'tuberculosi',\n",
       " 'diseas',\n",
       " 'spread',\n",
       " 'infect',\n",
       " 'suscept',\n",
       " 'individu',\n",
       " 'germ',\n",
       " 'inact',\n",
       " 'infect',\n",
       " 'high',\n",
       " 'risk',\n",
       " 'contract',\n",
       " 'peopl',\n",
       " 'capac',\n",
       " 'resist',\n",
       " 'infect',\n",
       " 'weaken',\n",
       " 'diseas',\n",
       " 'hiv',\n",
       " 'infect',\n",
       " 'drug',\n",
       " 'alcohol',\n",
       " 'abus',\n",
       " 'ill',\n",
       " 'cancer',\n",
       " 'poor',\n",
       " 'nutrit',\n",
       " 'greatest',\n",
       " 'concentr',\n",
       " 'tuberculosi',\n",
       " 'ag',\n",
       " 'group',\n",
       " 'account',\n",
       " 'total',\n",
       " 'men',\n",
       " 'outnumb',\n",
       " 'women',\n",
       " 'caseload']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  '0.015*\"diamond\" + 0.011*\"mine\" + 0.009*\"finsch\" + 0.009*\"jwaneng\" + 0.009*\"underground\"'),\n",
       " (0,\n",
       "  '0.023*\"bank\" + 0.015*\"world\" + 0.011*\"sai\" + 0.011*\"nafta\" + 0.010*\"countri\"'),\n",
       " (28,\n",
       "  '0.016*\"welfar\" + 0.015*\"build\" + 0.012*\"air\" + 0.012*\"ventil\" + 0.008*\"year\"'),\n",
       " (26,\n",
       "  '0.018*\"polic\" + 0.012*\"suspect\" + 0.011*\"said\" + 0.011*\"brutal\" + 0.009*\"offic\"'),\n",
       " (12,\n",
       "  '0.044*\"thoma\" + 0.016*\"limit\" + 0.016*\"court\" + 0.015*\"term\" + 0.011*\"black\"'),\n",
       " (17,\n",
       "  '0.018*\"race\" + 0.014*\"marathon\" + 0.012*\"second\" + 0.009*\"hale\" + 0.009*\"davi\"'),\n",
       " (27,\n",
       "  '0.022*\"said\" + 0.022*\"hurrican\" + 0.008*\"wind\" + 0.007*\"center\" + 0.006*\"sheet\"'),\n",
       " (6,\n",
       "  '0.026*\"eclips\" + 0.019*\"said\" + 0.012*\"offic\" + 0.009*\"smith\" + 0.009*\"polic\"'),\n",
       " (14,\n",
       "  '0.018*\"marathon\" + 0.015*\"said\" + 0.012*\"race\" + 0.011*\"year\" + 0.010*\"mile\"'),\n",
       " (23,\n",
       "  '0.030*\"taylor\" + 0.022*\"said\" + 0.014*\"hospit\" + 0.011*\"doctor\" + 0.010*\"pneumonia\"'),\n",
       " (29,\n",
       "  '0.018*\"path\" + 0.017*\"shine\" + 0.016*\"count\" + 0.016*\"censu\" + 0.014*\"said\"'),\n",
       " (8,\n",
       "  '0.036*\"slovenia\" + 0.021*\"yugoslavia\" + 0.019*\"sloven\" + 0.013*\"croatia\" + 0.012*\"republ\"'),\n",
       " (19,\n",
       "  '0.031*\"eclips\" + 0.015*\"sun\" + 0.011*\"said\" + 0.007*\"moon\" + 0.007*\"total\"'),\n",
       " (22,\n",
       "  '0.025*\"said\" + 0.015*\"oil\" + 0.012*\"exxon\" + 0.009*\"spill\" + 0.008*\"valdez\"'),\n",
       " (7,\n",
       "  '0.031*\"said\" + 0.018*\"crash\" + 0.009*\"plane\" + 0.009*\"engin\" + 0.008*\"air\"'),\n",
       " (2,\n",
       "  '0.015*\"polic\" + 0.013*\"said\" + 0.012*\"right\" + 0.006*\"offic\" + 0.006*\"state\"'),\n",
       " (11,\n",
       "  '0.018*\"hospit\" + 0.017*\"pneumonia\" + 0.015*\"taylor\" + 0.013*\"week\" + 0.012*\"miss\"'),\n",
       " (10,\n",
       "  '0.014*\"park\" + 0.014*\"slovenia\" + 0.014*\"year\" + 0.010*\"yellowston\" + 0.010*\"said\"'),\n",
       " (13,\n",
       "  '0.039*\"diabet\" + 0.016*\"said\" + 0.015*\"latino\" + 0.015*\"eclips\" + 0.011*\"health\"'),\n",
       " (18,\n",
       "  '0.015*\"said\" + 0.009*\"polic\" + 0.008*\"taylo\" + 0.008*\"assassin\" + 0.006*\"aquino\"')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.print_topics(num_words=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get topic distribution of the document = PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def get_topic_distribution(text, lda_model, dictionary, num_topics=30):\n",
    "    tokens = preprocess_string(text)\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    topic_dist = np.zeros(num_topics)\n",
    "    for topic_id, prob in lda_model.get_document_topics(bow):\n",
    "        topic_dist[topic_id] = prob\n",
    "    return topic_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def klsum_greedy(text, lda_model, dictionary, num_topics=30, max_sentences=10):\n",
    "    sentences = sent_tokenize(text)\n",
    "    pd_topic = get_topic_distribution(text, lda_model, dictionary, num_topics)\n",
    "    \n",
    "    selected = []\n",
    "    remaining = sentences.copy()\n",
    "    remaining = [s.strip() for s in sentences]\n",
    "    \n",
    "    for _ in range(max_sentences):\n",
    "        best_sent = None\n",
    "        best_score = float('inf')\n",
    "        \n",
    "        for sent in remaining:\n",
    "            candidate = ' '.join(selected + [sent])\n",
    "            ps_topic = get_topic_distribution(candidate, lda_model, dictionary, num_topics)\n",
    "            score = entropy(ps_topic, pd_topic)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_sent = sent\n",
    "        \n",
    "        if best_sent:\n",
    "            selected.append(best_sent)\n",
    "            remaining.remove(best_sent)\n",
    "\n",
    "    return ' '.join(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 301/301 [01:50<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KL-Sum (Topic distribution) - average ROUGE score:\n",
      "ROUGE-1     average: 0.4595\n",
      "ROUGE-2     average: 0.3584\n",
      "ROUGE-L     average: 0.4590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "rouge1_scores = []\n",
    "rouge2_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for doc_text, gold_summary in tqdm(zip(documents, gold_summaries), total=len(documents)):\n",
    "    try:\n",
    "        sentences = sent_tokenize(doc_text)\n",
    "        num_sentences = len(sentences)\n",
    "        max_sentences = ceil(num_sentences * 0.25)\n",
    "        pred_summary = klsum_greedy(doc_text, lda_model, dictionary, num_topics=30, max_sentences=max_sentences)\n",
    "\n",
    "        pred_summary_clean = pred_summary.strip().replace('\\n', ' ')\n",
    "        gold_summary_clean = gold_summary.strip().replace('\\n', ' ')\n",
    "\n",
    "        results = rouge.get_scores(pred_summary_clean, gold_summary_clean)[0]\n",
    "\n",
    "        rouge1_scores.append(results['rouge-1']['f'])\n",
    "        rouge2_scores.append(results['rouge-2']['f'])\n",
    "        rougeL_scores.append(results['rouge-l']['f'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[SKIP] error: {e}\")\n",
    "        continue\n",
    "\n",
    "avg_r1 = sum(rouge1_scores) / len(rouge1_scores) if rouge1_scores else 0\n",
    "avg_r2 = sum(rouge2_scores) / len(rouge2_scores) if rouge2_scores else 0\n",
    "avg_rl = sum(rougeL_scores) / len(rougeL_scores) if rougeL_scores else 0\n",
    "\n",
    "print(\"\\nKL-Sum (Topic distribution) - average ROUGE score:\")\n",
    "print(f\"ROUGE-1     average: {avg_r1:.4f}\")\n",
    "print(f\"ROUGE-2     average: {avg_r2:.4f}\")\n",
    "print(f\"ROUGE-L     average: {avg_rl:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word distribution Rouge score:\n",
    "\n",
    "ROUGE-1 F1: 0.6064\n",
    "ROUGE-2 F1: 0.5027\n",
    "ROUGE-L F1: 0.6060"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic distribution Rouge score:\n",
    "\n",
    "ROUGE-1     average: 0.4595\n",
    "ROUGE-2     average: 0.3584\n",
    "ROUGE-L     average: 0.4590"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word distribution-based summarization tends to have higher ROUGE scores due to more direct word overlap with the reference summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic distribution-based summarization focuses on capturing key ideas or themes, which may result in lower surface-level word overlap and thus lower ROUGE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ROUGE evaluates lexical overlap, so the score of topic-based summaries may have less than word-based summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
