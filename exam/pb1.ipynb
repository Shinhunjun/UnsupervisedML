{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a39c8b46",
   "metadata": {},
   "source": [
    "TA's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb08dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_labels: np.ndarray, pred_labels: np.ndarray) -> tuple:\n",
    "    \"\"\"Entropy-based evaluation of a label assignment.\n",
    "\n",
    "    Parameters:\n",
    "      true_labels: the ground-truth class labels on the input data.\n",
    "      pred_labels: the predicted class labels on the input data.\n",
    "\n",
    "    Returns:\n",
    "      a tuple (CM, (cs_e, cr_e, we)) containing the confusion matrix `CM`, the class entropies `cs_e`,\n",
    "      the cluster entropies `cr_e`, and the averaged weighted entropies `we`.\n",
    "    \"\"\"\n",
    "    from scipy.stats import entropy\n",
    "    import numpy as np\n",
    "\n",
    "    assert len(true_labels) == len(pred_labels), \"Label predictions don't match\"\n",
    "\n",
    "    \n",
    "    t_classes, t_labels = np.unique(true_labels, return_inverse=True)\n",
    "    p_classes, p_labels = np.unique(pred_labels, return_inverse=True)\n",
    "    assert np.all(np.isin(p_classes, t_classes)), \"Predicted class outside of labels given\"\n",
    "\n",
    "    \n",
    "    n_classes = len(t_classes)\n",
    "    CM = np.zeros(shape=(n_classes, n_classes), dtype=np.uint32)\n",
    "    ind = np.ravel_multi_index([t_labels, p_labels], CM.shape)\n",
    "    np.add.at(CM.ravel(), ind, 1)\n",
    "\n",
    "    \n",
    "    def empirical_dist(x):\n",
    "        return x / np.sum(x) if np.sum(x) > 0 else x\n",
    "\n",
    "    cluster_entropy = np.apply_along_axis(lambda x: entropy(empirical_dist(x), base=2), 0, CM)\n",
    "    class_entropy  = np.apply_along_axis(lambda x: entropy(empirical_dist(x), base=2), 1, CM)\n",
    "\n",
    "    \n",
    "    N = len(true_labels)\n",
    "    w_cluster_entropy = np.sum(cluster_entropy * CM.sum(axis=0)) / N\n",
    "    w_class_entropy   = np.sum(class_entropy  * CM.sum(axis=1)) / N\n",
    "    w_entropies = np.array([w_class_entropy, w_cluster_entropy])\n",
    "\n",
    "    with np.printoptions(precision=3):\n",
    "        print(f\"Class Entropies: {class_entropy}\")\n",
    "        print(f\"Cluster Entropies: {cluster_entropy}\")\n",
    "        print(f\"Weighted average entropies: {w_entropies}, (avg: {np.mean(w_entropies):.3f})\")\n",
    "\n",
    "    return CM, (w_class_entropy, w_cluster_entropy, w_entropies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1f04e",
   "metadata": {},
   "source": [
    "Gaussian Mixture soft kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4236aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dims = 16 components\n",
      "Confusion Matrix:\n",
      " [[  0  26   0   0   0  12   3   6  57 568]\n",
      " [679  31   6 843   3   7   5   1   5   0]\n",
      " [  1  30   7   1   4 195  24   6 219   3]\n",
      " [  2 562  21  10  18 121   0   4 278   2]\n",
      " [  2   5 452   1 413  32  29  11  14   2]\n",
      " [  0 374   9   4  14 108   6 626  42  30]\n",
      " [  2  23   1   8   0  31 618   9  15  21]\n",
      " [  4  11 125   7 338   9   1   1  19   0]\n",
      " [  6 187  12   8  43  61   4  44 126   4]\n",
      " [  1  22 266   8 360  19   0   2   7   1]]\n",
      "Label Entropies:   [0.888 1.26  1.812 1.7   1.601 1.818 1.001 1.464 2.438 1.515]\n",
      "Cluster Entropies: [0.238 2.116 1.804 0.442 1.956 2.666 0.705 0.791 2.422 0.659]\n",
      "Weighted Entropies (class,cluster): [1.517 1.454] (avg: 1.485)\n",
      "\n",
      "Weighted entropies: class=1.517, cluster=1.454, avg=1.485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import entropy\n",
    "\n",
    "data   = np.loadtxt('pb1data_XW_8358.txt', delimiter=',')\n",
    "labels = data[:, 0].astype(int)\n",
    "pixels = data[:, 1:].reshape(-1, 28, 28).astype(np.float32)\n",
    "\n",
    "denoised = np.array([gaussian_filter(img, sigma=1) for img in pixels])\n",
    "X_blur   = denoised.reshape(-1, 784)\n",
    "\n",
    "scaler   = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_blur)\n",
    "\n",
    "pca = PCA(n_components=0.4, whiten=True, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"PCA dims = {X_pca.shape[1]} components\")\n",
    "\n",
    "gmm = GaussianMixture(\n",
    "    n_components=10,\n",
    "    covariance_type='full',\n",
    "    n_init=10,\n",
    "    max_iter=500,\n",
    "    random_state=42\n",
    ")\n",
    "pred= gmm.fit_predict(X_pca)\n",
    "\n",
    "CM, (cs_e, cr_e, w_entropies) = evaluate(labels, pred)\n",
    "print(\"Weighted entropies: class={:.3f}, cluster={:.3f}, avg={:.3f}\"\n",
    "      .format(w_entropies[0], w_entropies[1], w_entropies.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c620d3fc",
   "metadata": {},
   "source": [
    "Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f91fb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dims = 113 components\n",
      "Confusion Matrix:\n",
      " [[  1   6  14   0 357   3  30  50 210   1]\n",
      " [  6   2   9 786   0   3  10   1   5 758]\n",
      " [ 11  10 326   4   4   7   8  33  67  20]\n",
      " [ 15  12  32  15   0  13  16 302 608   5]\n",
      " [283 209  32   6   4 369  24   4   3  27]\n",
      " [ 20  14  19  17   4  37 465 310 319   8]\n",
      " [  2   0 598   5  40   1   1   7  63  11]\n",
      " [ 39 240   5  12   1 185  10   0   7  16]\n",
      " [ 14  51   8  13   2  44  63  95 171  34]\n",
      " [155 181   3  12   3 305   2   3  17   5]]\n",
      "Label Entropies:   [1.728 1.191 1.769 1.588 2.107 2.121 1.023 1.885 2.691 1.925]\n",
      "Cluster Entropies: [1.963 2.188 1.655 0.733 0.815 2.092 1.49  2.002 2.322 0.989]\n",
      "Weighted Entropies (class,cluster): [1.734 1.702] (avg: 1.718)\n",
      "\n",
      "KMeans avg entropy: 1.7181191048421192\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data   = np.loadtxt('pb1data_XW_8358.txt', delimiter=',')\n",
    "labels = data[:,0].astype(int)\n",
    "\n",
    "pixels = data[:,1:].reshape(-1,28,28).astype(np.float32)\n",
    "\n",
    "denoised_imgs = np.array([gaussian_filter(img, sigma=1) for img in pixels])\n",
    "X_blur = denoised_imgs.reshape(-1, 784)\n",
    "\n",
    "scaler   = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_blur)\n",
    "\n",
    "pca   = PCA(n_components=0.90, whiten=True, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "print(f\"PCA dims = {X_pca.shape[1]} components\")\n",
    "\n",
    "kmeans    = KMeans(n_clusters=10, n_init=100, max_iter=500, random_state=42)\n",
    "labels_km = kmeans.fit_predict(X_pca)\n",
    "\n",
    "CM_km, (cs_e, cr_e, w_entropies) = evaluate(labels, labels_km)\n",
    "print(\"KMeans avg entropy:\", w_entropies.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef65179a",
   "metadata": {},
   "source": [
    "Answerr : 1.4 was the best i could get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef766cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
